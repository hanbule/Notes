# 1
Tokenize text into tokens:
    def tokenize_1(text):
        if(text=="" or text!=text):
            return text
        else:
            tokens = re.split("(?<! ั.ะต)(?<!\\.)\\. +(?!\\.)(?!com)|(?<![0-9]), *(?![0-9])| +", text)
            return tokens

# 2
Get list of unique tokens from text:
    def get_uniq_tokens(s):
        if(s == "" or s!=s):
            return s
        else:
            tokens = tokenize_1(s)
            tokens = list(set(tokens))
            return tokens
